{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You have the choice of doing either (1) an AI solve a problem style project or (2) run a Special Topics class on a topic of your choice.  If you want to do (2) you should fill out the _other_ proposal for that. This is the proposal description for (1).\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like 8-Queens or a small Traveling Salesman Problem or similar\n",
    "- If its the kind of problem (e.g., RL) that interacts with a simulator or live task, then the problem will have a reasonably complex action space. For instance, a wupus world kind of thing with a 9x9 grid is definitely too small.  A simulated mountain car with a less complex 2-d road and simplified dynamics seems like a fairly low achievement level.  A more complex 3-d mountain car simulation with large extent and realistic dynamics, sure sounds great!\n",
    "- If its the kind of problem that uses a dataset, then the dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training an unsupervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "- The project must include some elements we talked about in the course\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your AI system. Generally RL tasks may require a huge amount of training, so extensive grid search is unlikely to be possible. However expoloring a few reasonable hyper-parameters may still be possible. \n",
    "- You will evaluate the performance of your AI system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Wendy Shi\n",
    "- Maria Balderas\n",
    "- Madeline Blount\n",
    "- Linlin Zheng "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The goal with this project is to optimize the playing strategy of the arcade video game Pac-Man using AI algorithms, in which the strategy aims for the number of points to be maximized and ghost encounters/lives lost to be minimized. For our implementation we will be using variables relating to the current game state, such as presence/location of ghosts (ghost encounters will remove one of your lives), point pellets(collecting them gives you points), power ups (allow you to do various things like eat ghosts and will reward you with points if you do so), and current location. These features will be used to train and test the various AI algorithms we plan on implementing with the goal of finding the one that optimizes its strategy the best. Performance/ success of each algorithm will be measured by how effectively it consistently maximizes the number of points, while minimizing the lives lost, in the shortest time possible. The models will be trained by extensive simulated gameplay and compared to each other.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 3 to 5 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. \n",
    "\n",
    "\n",
    "Pac-man, originally called Puck-man in Japan, is a 1980 maze video game[1] developed and published by Namco for arcades. The player controls Pac-Man, who must eat all the dots inside an enclosed mae while avoiding four colored ghosts – Blinky(red), Pinky(pink), Inky(cyan), and Clyde(orange) – who pursue Pac-Man. When Pac-Man eats all of the dots, the player advances to the next level. Levels are indicated by fruit icons at the bottom of the screen. In between levels are short cutscenes featuring Pac-Man and Blinky in humorous, comical situations. If a ghost catches Pac-Man, he loses a life; the game ends when all lives are lost. Each of the four ghosts has its own unique artificial intelligence (A.I.), or \"personality\": Blinky gives direct chase to Pac-Man; Pinky and Inky try to position themselves in front of Pac-Man, usually by cornering him; and Clyde switches between chasing Pac-Man and fleeing from him.[2]\n",
    "\n",
    "In this project, we will explore AI techniques for controlling ghost behaviors using rule-based systems and finite-state machines[3]. Additionally, we will implement Monte Carlo Tree Search (MCTS) to optimize Pac-Man’s movement based on expected outcomes, demonstrating that a lookahead-based approach can significantly improve performance compared to simpler heuristic strategies. This research aims to enhance AI decision-making in real-time environments by refining existing methodologies and exploring their applications in broader AI fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem being solved is Pac-Man’s playing strategy in search of achieving the highest number of points while minimizing the number of lives lost. The Pac-Man environment is a dynamic one in which  decisions are made based on walls, current position, position of the ghosts, position of power ups (fruits) and point pellets. The problem is quantifiable as we can get a score number and number of lives, it is measurable as its success is also determined based on these quantifiable measures even including level number, or survival time. It is also replicable as (at least in our implementation) the game can be played in either identical conditions or varied similar ones. \n",
    "\n",
    "One way we can provide a solution for this problem is through reinforcement learning, where a reward based feedback (one that naturally occurs in the game as you consume pellets) helps improve decision making. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "You should have a strong idea of what dataset(s) will be used to accomplish this project. \n",
    "\n",
    "If you know what (some) of the data you will use, please give the following information for each dataset:\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc will be needed\n",
    "\n",
    "If you don't yet know what your dataset(s) will be, you should describe what you desire in terms of the above bullets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "To solve the problem of optimizing Pac-Man’s playing strategy, we propose using Reinforcement Learning (RL) as the primary approach. Specifically, we will implement a Deep Q-Network (DQN), which is an extension of Q-learning that incorporates deep neural networks to approximate the optimal Q-values for state-action pairs. Our approach will enable the AI agent to learn an optimal policy by interacting with the Pac-Man environment and maximizing cumulative rewards.\n",
    "\n",
    "We propose using Deep Q-Networks (DQN) to optimize Pac-Man’s strategy through Reinforcement Learning (RL). The AI agent will learn an optimal policy by interacting with the game environment and maximizing cumulative rewards.\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1. State Representation: Encodes Pac-Man’s position, ghost locations, power-ups, pellets, and score.\n",
    "2. Action Space: Four moves—Up, Down, Left, Right.\n",
    "3. Reward Function:\n",
    "    - +10 for pellets, +50 for power-ups, +200 for eating ghosts.\n",
    "    - -100 for getting caught, +500 for level completion.\n",
    "    - Small penalties to encourage efficiency.\n",
    "\n",
    "**Model Implementation**\n",
    "\n",
    "- DQN with Experience Replay to store and learn from past actions.\n",
    "- Epsilon-greedy strategy to balance exploration and exploitation.\n",
    "- Bellman Equation updates Q-values for optimal decision-making.\n",
    "\n",
    "**Benchmark & Evaluation**\n",
    "\n",
    "- Baseline Heuristic Model: Moves toward pellets, avoids ghosts, prioritizes power-ups.\n",
    "- Performance Metrics:\n",
    "    - Cumulative score, levels completed, survival time, and ghosts eaten per power-up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "To evaluate the performance of our model, we will count the cumulative reward of the agent in each game. We will also measure how well the agent avoids the ghosts, measured by both whether or not the agent gets eaten by a ghost, and if so, how long they were able to avoid the ghosts. To evaluate how well the model is learning the game, we will count the cumulative reward of each episode, and analyze whether or not the cumulative reward is increasing across episodes. For the ability to avoid ghosts, we will similarly track the amount of time the agent gets caught by a ghost, if at all, across many episodes and see if that time decreases. We will likely also keep a count of how often the agent gets caught by a ghost, regardless of the exact time, to see if the frequency of getting caught decreases across more and more episodes. For both metrics, we will likely create data visualizations to help visualize whether the agent is effectively learning the game. \n",
    "\n",
    "Additionally, we may create a data model such as a linear regression model or a rolling mean to quantify how well the model is learning, and possibly compare those metrics with metrics from other models. A rolling mean is derived by taking the average over a specific number of past trials (rather than all of the trials), also called a “window size.” Taking a rolling window size for the average helps to deconflate the impact of outliers, as well as view progress better than an overall average. We may also use linear regression, which finds the best fitting straight line, to get a metric for the rate of learning, which could allow us to easily compare how effectively our model is learning compared to other models. Some possible issues with this method is that reinforcement learning might not be well modeled with a linear regression model, so it would just be used to give us a rough metric for how our model is stacking up to others, and whether or not it is learning at all. \n",
    "\n",
    "**Derivation of rolling mean and mathematical representation:**\n",
    "\n",
    "The rolling average can be represented by the following equation:\n",
    "\n",
    "$$\n",
    "R_{\\text{smooth},t} = \\frac{1}{N} \\sum_{i=t-N+1}^{t} R_i\n",
    "$$\n",
    "\n",
    "Where N is the window size, or number of past samples that we want to include in our average, and Ri represents our data points. This method works by taking the average at every time step, using the last N number of samples. \n",
    "\n",
    "\n",
    "**Derivation of linear regression and mathematical representation:**\n",
    "\n",
    "Linear regression finds the best fitting straight line through a data set, and can be represented with the equation:\n",
    "\n",
    "$$\n",
    "y = mx + b\n",
    "$$\n",
    "\n",
    "Where x is the input data, y is the estimated output, m is the slope of the line, and b is the y-intercept. \n",
    "\n",
    "\n",
    "**Additionally, the fit of the line to the data can be measured by the sum of square errors:**\n",
    "\n",
    "$$\n",
    "SSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Where yi is the predicted value. This equation measures the distance between the data points to the line, which helps evaluate how well the line is fitting to the data. A linear regression model takes the slope that results in the smallest SSE, signifying the least possible distance between data points and its graphical representation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project, the main possible areas of ethical issues lie in analysis and modeling. For example, we want to be aware that our model is not relying on heuristics or proxies that are unfairly discriminatory. Honest and unbiased analysis is also something we will need to consider, since different forms of analysis may lead us to different conclusions, which could result in misjudging the effectiveness of one model over another. \n",
    "There are also potential ethical and privacy issues if we decide to compare our model with data from real people playing this game. In this case, we would probably be using a dataset off of the internet, and in cases like these, there is always the possibility that a person did not fully understand the ways in which their data was going to be used, and did not read the fine print of the consent form. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1: Communication expectations. Project discussions between members will use DISCORD. Meet virtually (ZOOM) or face-to-face at least once a week, and no member should be absent during the discussion.*\n",
    "* *Team Expectation 2: Tone expectations. It is recommended to use a tone like \"blunt but polite\" when communicating between members.*\n",
    "* *Team Expectation 3: Decision expectations. All decisions will be made unanimously by majority vote. If a decision must be made in a short period of time and a member does not respond, the person involved can make the decision immediately.*\n",
    "* *Team Expectation 4: Everyone will do a little bit of everything. Tasks will be assigned to each member after discussion by each member. The whole team views the current task list and checks its progress through DISCORD.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 07:03:16) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
